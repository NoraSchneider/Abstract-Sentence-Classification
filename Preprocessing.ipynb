{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c81c787",
   "metadata": {},
   "source": [
    "# Task 0: Preprocessing of data\n",
    "\n",
    "The [data](https://github.com/Franck-Dernoncourt/pubmed-rct) consists of 200k abstracts from PubMed. Each sentence of a abstract is labeld with its role in the abstract (background, objective, method, result, or conclusion). In this notebook we preprocess the data for training our embeddings and models for classifications task 1 and 2. Preprocessing consists of the following steps\n",
    "- lower casing, tokenization, remove punctuation\n",
    "- optional: remove placeholder \"@\" for numbers\n",
    "- stop word removal\n",
    "- lemmatization or stemming or neither\n",
    "\n",
    "In addition we want to use the information that is given by the abstracts. Therefore we construct an additional feature called *relative_linenumber* that measure the relative position of a sentence in an abstract:\n",
    "\n",
    "$\\text{relative_linenumber} = \\frac{\\text{index of the sentence in an abstract}}{\\text{# of sentences in the abstract}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48b16997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/noraschneider/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/noraschneider/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/noraschneider/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/noraschneider/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/noraschneider/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import project2Lib\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82dd4c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nicely(n, df):\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        print(\"----------------------\")\n",
    "        r = []\n",
    "        for i in range(len(df.columns)):\n",
    "            r.append(row[i])\n",
    "        print(r)\n",
    "        \n",
    "        if(index >=n):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41592382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>linenumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The emergence of HIV as a chronic condition me...</td>\n",
       "      <td>24491034</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>This paper describes the design and evaluation...</td>\n",
       "      <td>24491034</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>This study is designed as a randomised control...</td>\n",
       "      <td>24491034</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>The intervention group will participate in the...</td>\n",
       "      <td>24491034</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>The program is based on self-efficacy theory a...</td>\n",
       "      <td>24491034</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           sentence  abstract_id  \\\n",
       "0      0  The emergence of HIV as a chronic condition me...     24491034   \n",
       "1      0  This paper describes the design and evaluation...     24491034   \n",
       "2      2  This study is designed as a randomised control...     24491034   \n",
       "3      2  The intervention group will participate in the...     24491034   \n",
       "4      2  The program is based on self-efficacy theory a...     24491034   \n",
       "\n",
       "   linenumber  \n",
       "0         0.0  \n",
       "1         0.1  \n",
       "2         0.2  \n",
       "3         0.3  \n",
       "4         0.4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data as dataframe\n",
    "train_data, dev_data, test_data = project2Lib.load_data_as_dataframe(data_dir=Path(\"./data\"), linenumber=True)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e56e734f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [09:14<00:00, 554.32s/it]\n"
     ]
    }
   ],
   "source": [
    "# Removing @ placeholder for numbers\n",
    "mode = [\"\", \"lemmatization\", \"stemming\"]\n",
    "for m in tqdm(mode):\n",
    "    train_data['preprocess'] = train_data['sentence'].apply(lambda x: project2Lib.preprocess_text(x, mode=m, remove_numplaceholder=True))\n",
    "    train_data.to_csv(f\"./PreprocessedData/train_{m}_noph.csv\")\n",
    "    dev_data['preprocess'] = dev_data['sentence'].apply(lambda x: project2Lib.preprocess_text(x, mode=m, remove_numplaceholder=True))\n",
    "    dev_data.to_csv(f\"./PreprocessedData/dev_{m}_noph.csv\")\n",
    "    test_data['preprocess'] = test_data['sentence'].apply(lambda x: project2Lib.preprocess_text(x, mode=m, remove_numplaceholder=True))\n",
    "    test_data.to_csv(f\"./PreprocessedData/test_{m}_noph.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4affa609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping @ placeholder for numbers\n",
    "mode = [\"lemmatization\"]\n",
    "for m in tqdm(mode):\n",
    "    train_data['preprocess'] = train_data['sentence'].apply(lambda x: project2Lib.preprocess_text(x, mode=m, remove_numplaceholder=False))\n",
    "    train_data.to_csv(f\"./PreprocessedData/train_{m}.csv\")\n",
    "    dev_data['preprocess'] = dev_data['sentence'].apply(lambda x: project2Lib.preprocess_text(x, mode=m, remove_numplaceholder=False))\n",
    "    dev_data.to_csv(f\"./PreprocessedData/dev_{m}.csv\")\n",
    "    test_data['preprocess'] = test_data['sentence'].apply(lambda x: project2Lib.preprocess_text(x, mode=m, remove_numplaceholder=False))\n",
    "    test_data.to_csv(f\"./PreprocessedData/test_{m}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16d3a08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [14:37<00:00, 877.34s/it]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing of small dataset\n",
    "# Load data as dataframe\n",
    "train_data_small, dev_data_small, test_data_small = project2Lib.load_data_as_dataframe(data_dir=Path(\"./data_small\"), linenumber=True)\n",
    "\n",
    "# Keeping @ placeholder for numbers\n",
    "mode = [\"lemmatization\"]\n",
    "for m in tqdm(mode):\n",
    "    train_data_small['preprocess'] = train_data_small['sentence'].apply(lambda x: project2Lib.preprocess_text(x, mode=m, remove_numplaceholder=False))\n",
    "    train_data_small.to_csv(f\"./PreprocessedData/train_{m}_small.csv\")\n",
    "    dev_data_small['preprocess'] = dev_data_small['sentence'].apply(lambda x: project2Lib.preprocess_text(x, mode=m, remove_numplaceholder=False))\n",
    "    dev_data_small.to_csv(f\"./PreprocessedData/dev_{m}_small.csv\")\n",
    "    test_data_small['preprocess'] = test_data_small['sentence'].apply(lambda x: project2Lib.preprocess_text(x, mode=m, remove_numplaceholder=False))\n",
    "    test_data_small.to_csv(f\"./PreprocessedData/test_{m}_small.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df3a5e5",
   "metadata": {},
   "source": [
    "## Relevance of relative position\n",
    "\n",
    "We suspect that a lot of information for the classification task is carried in the relative position of a sentence in the abstract. To demonstrate the power of this feature, we train a simple logistic regression, just based on this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7839c254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noraschneider/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/arraysetops.py:583: FutureWarning:\n",
      "\n",
      "elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "datasets = [\"train\", \"dev\", \"test\"]\n",
    "filepaths = []\n",
    "for i in datasets: \n",
    "    filepaths.append(f\"./PreprocessedData/{i}_lemmatization_noph.csv\")\n",
    "    \n",
    "train_data = pd.read_csv(filepaths[0], index_col = 0)\n",
    "train_data = train_data.fillna('')\n",
    "dev_data = pd.read_csv(filepaths[1], index_col = 0)\n",
    "dev_data = dev_data.fillna('')\n",
    "test_data = pd.read_csv(filepaths[2], index_col = 0)\n",
    "test_data = test_data.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e64e3424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.6817444661972296\n",
      "Accuracy: 0.7141016512392772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-11.01463154],\n",
       "        [-18.04791756],\n",
       "        [ -3.12187785],\n",
       "        [  6.25828715],\n",
       "        [ 25.9261398 ]]),\n",
       " array([0, 1, 2, 3, 4]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and evaluate simple logistic regression\n",
    "Y_train = train_data[\"label\"]\n",
    "Y_dev = dev_data[\"label\"]\n",
    "Y_test = test_data[\"label\"]\n",
    "\n",
    "X_train = train_data[\"line_relative\"].values\n",
    "X_dev = dev_data[\"line_relative\"].values\n",
    "X_test = test_data[\"line_relative\"].values\n",
    "\n",
    "clf = LogisticRegression(random_state=123, max_iter = 500).fit(X_train.reshape(-1, 1), Y_train)\n",
    "\n",
    "y_hat_test = clf.predict(X_test.reshape(-1, 1))\n",
    "f1 = f1_score(Y_test, y_hat_test,average=\"weighted\")\n",
    "acc = accuracy_score(Y_test, y_hat_test)\n",
    "print(f\"F1 score: {f1}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "clf.coef_, clf.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a20968b",
   "metadata": {},
   "source": [
    "F1 score: 0.6817444661972296\n",
    "\n",
    "Accuracy: 0.7141016512392772\n",
    "\n",
    "(array([[-11.01463154],\n",
    "\n",
    "        [-18.04791756],\n",
    "        \n",
    "        [ -3.12187785],\n",
    "        \n",
    "        [  6.25828715],\n",
    "        \n",
    "        [ 25.9261398 ]]),\n",
    " array([0, 1, 2, 3, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45348ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.180058888669869\n",
      "Accuracy: 0.34842165937680125\n"
     ]
    }
   ],
   "source": [
    "# compare to random guessing\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import numpy as np\n",
    "dummy_clf = DummyClassifier(strategy=\"prior\")\n",
    "dummy_clf.fit(X_train.reshape(-1, 1), Y_train)\n",
    "\n",
    "y_hat_test = dummy_clf.predict(X_test.reshape(-1, 1))\n",
    "f1 = f1_score(Y_test, y_hat_test,average=\"weighted\")\n",
    "acc = accuracy_score(Y_test, y_hat_test)\n",
    "print(f\"F1 score: {f1}\")\n",
    "print(f\"Accuracy: {acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4hc2",
   "language": "python",
   "name": "ml4hc2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
